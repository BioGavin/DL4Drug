{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Protein Sequence Representation Model\n",
    "\n",
    "TorchProtein定义了多种基于序列的模型来学习蛋白质序列表示。在本教程中，我们使用一个两层的一维卷积神经网络（1D CNN）作为所有考虑任务的蛋白质序列表示模型。首先，让我们通过models.ProteinCNN模块来定义这样一个模型。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-07T09:34:01.786804Z",
     "start_time": "2024-02-07T09:33:57.740039Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchdrug import models\n",
    "\n",
    "model = models.ProteinCNN(input_dim=21,\n",
    "                          hidden_dims=[1024, 1024],\n",
    "                          kernel_size=5, padding=2, readout=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 1: Protein-wise Property Prediction\n",
    "\n",
    "我们希望解决的第一类任务是预测蛋白质的整体性质。我们以β-内酰胺酶活性预测任务为例，该任务旨在预测对TEM-1 β-内酰胺酶蛋白的突变效应。\n",
    "\n",
    "在定义数据集之前，我们首先需要定义我们要对蛋白质执行的转换操作。我们考虑两种转换操作：（1）为了降低基于序列的模型的内存成本，常见做法是截断过长的蛋白质序列。在TorchProtein中，我们可以通过指定最大长度（max_length参数）和截断位置（随机残基或第一个残基）（random参数）来定义蛋白质截断转换。 （2）此外，由于我们希望将残基特征作为序列模型的节点特征使用，我们还需要定义蛋白质的视图转换。在数据集构建过程中，我们可以将两个转换的组合作为参数传递。\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torchdrug import transforms\n",
    "\n",
    "truncate_transform = transforms.TruncateProtein(max_length=200, random=False)\n",
    "protein_view_transform = transforms.ProteinView(view=\"residue\")\n",
    "transform = transforms.Compose([truncate_transform, protein_view_transform])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T09:36:25.990493Z",
     "start_time": "2024-02-07T09:36:25.250626Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "然后，我们通过datasets.BetaLactamase构建数据集，该数据集文件将自动下载。在这个数据集中，每个样本的标签是一个实数，表示蛋白质的适应性值。通过打开residue_only选项，TorchProtein将使用data.Protein.from_sequence_fast来加载蛋白质，从而提高加载速度。我们可以通过split()方法获取预定义的训练、验证和测试集划分。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:53:58   Extracting /home/weibin/protein-datasets/beta_lactamase.tar.gz to /home/weibin/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing proteins from sequences: 100%|██████████| 5198/5198 [00:10<00:00, 518.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of first sample:  0.9426838159561157\n",
      "train samples: 4158, valid samples: 520, test samples: 520\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import datasets\n",
    "\n",
    "dataset = datasets.BetaLactamase(\"~/protein-datasets/\", atom_feature=None, bond_feature=None, residue_feature=\"default\", transform=transform)\n",
    "train_set, valid_set, test_set = dataset.split()\n",
    "print(\"The label of first sample: \", dataset[0][dataset.target_fields[0]])\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" % (len(train_set), len(valid_set), len(test_set)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T10:54:08.611854Z",
     "start_time": "2024-02-07T10:53:58.014638Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了进行β-内酰胺酶活性预测，我们将CNN编码器包装在tasks.PropertyPrediction模块中，该模块在CNN之上添加了一个特定任务的MLP预测头。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torchdrug import tasks\n",
    "\n",
    "task = tasks.PropertyPrediction(model, task=dataset.tasks,\n",
    "                                criterion=\"mse\", metric=(\"mae\", \"rmse\", \"spearmanr\"),\n",
    "                                normalization=False, num_mlp_layer=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T10:56:28.116494Z",
     "start_time": "2024-02-07T10:56:27.558548Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "现在我们可以训练我们的模型了。我们为模型设置了一个优化器，并将所有内容放在一个Engine实例中。在这个任务上，我们的模型训练10个epochs大约需要2分钟的时间。最后，我们评估模型在验证集上的性能。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:59:35   Preprocess training set\n",
      "18:59:49   {'batch_size': 64,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.0001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.PropertyPrediction',\n",
      "          'criterion': 'mse',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('mae', 'rmse', 'spearmanr'),\n",
      "          'model': {'activation': 'relu',\n",
      "                    'class': 'models.ProteinConvolutionalNetwork',\n",
      "                    'concat_hidden': False,\n",
      "                    'hidden_dims': [1024, 1024],\n",
      "                    'input_dim': 21,\n",
      "                    'kernel_size': 5,\n",
      "                    'padding': 2,\n",
      "                    'readout': 'max',\n",
      "                    'short_cut': False,\n",
      "                    'stride': 1},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'task': ['scaled_effect1'],\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'datasets.BetaLactamase',\n",
      "                          'path': '~/protein-datasets/',\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb229fae7f0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7fb229fae190>]},\n",
      "                          'verbose': 1},\n",
      "              'indices': range(4678, 5198)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.BetaLactamase',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb229fae7f0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fb229fae190>]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 4158)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.BetaLactamase',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb229fae7f0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fb229fae190>]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(4158, 4678)}}\n",
      "18:59:49   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "18:59:49   Epoch 0 begin\n",
      "18:59:53   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "18:59:53   mean squared error: 0.581154\n",
      "19:00:08   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:08   Epoch 0 end\n",
      "19:00:08   duration: 18.28 secs\n",
      "19:00:08   speed: 3.56 batch / sec\n",
      "19:00:08   ETA: 2.74 mins\n",
      "19:00:08   max GPU memory: 1502.9 MiB\n",
      "19:00:08   ------------------------------\n",
      "19:00:08   average mean squared error: 0.116417\n",
      "19:00:08   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:08   Epoch 1 begin\n",
      "19:00:16   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:16   mean squared error: 0.0943052\n",
      "19:00:22   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:22   Epoch 1 end\n",
      "19:00:22   duration: 14.22 secs\n",
      "19:00:22   speed: 4.57 batch / sec\n",
      "19:00:22   ETA: 2.17 mins\n",
      "19:00:22   max GPU memory: 1502.9 MiB\n",
      "19:00:22   ------------------------------\n",
      "19:00:22   average mean squared error: 0.100304\n",
      "19:00:22   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:22   Epoch 2 begin\n",
      "19:00:34   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:34   Epoch 2 end\n",
      "19:00:34   duration: 12.26 secs\n",
      "19:00:34   speed: 5.30 batch / sec\n",
      "19:00:34   ETA: 1.74 mins\n",
      "19:00:34   max GPU memory: 1502.9 MiB\n",
      "19:00:34   ------------------------------\n",
      "19:00:34   average mean squared error: 0.100038\n",
      "19:00:34   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:34   Epoch 3 begin\n",
      "19:00:35   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:35   mean squared error: 0.153223\n",
      "19:00:45   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:45   Epoch 3 end\n",
      "19:00:45   duration: 10.84 secs\n",
      "19:00:45   speed: 6.00 batch / sec\n",
      "19:00:45   ETA: 1.39 mins\n",
      "19:00:45   max GPU memory: 1502.9 MiB\n",
      "19:00:45   ------------------------------\n",
      "19:00:45   average mean squared error: 0.0996635\n",
      "19:00:45   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:45   Epoch 4 begin\n",
      "19:00:52   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:52   mean squared error: 0.121921\n",
      "19:00:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:57   Epoch 4 end\n",
      "19:00:57   duration: 11.68 secs\n",
      "19:00:57   speed: 5.56 batch / sec\n",
      "19:00:57   ETA: 1.12 mins\n",
      "19:00:57   max GPU memory: 1502.9 MiB\n",
      "19:00:57   ------------------------------\n",
      "19:00:57   average mean squared error: 0.0982756\n",
      "19:00:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:00:57   Epoch 5 begin\n",
      "19:01:08   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:08   Epoch 5 end\n",
      "19:01:08   duration: 11.73 secs\n",
      "19:01:08   speed: 5.54 batch / sec\n",
      "19:01:08   ETA: 52.68 secs\n",
      "19:01:08   max GPU memory: 1502.9 MiB\n",
      "19:01:08   ------------------------------\n",
      "19:01:08   average mean squared error: 0.0964227\n",
      "19:01:08   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:08   Epoch 6 begin\n",
      "19:01:10   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:10   mean squared error: 0.104743\n",
      "19:01:20   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:20   Epoch 6 end\n",
      "19:01:20   duration: 11.13 secs\n",
      "19:01:20   speed: 5.84 batch / sec\n",
      "19:01:20   ETA: 38.63 secs\n",
      "19:01:20   max GPU memory: 1502.9 MiB\n",
      "19:01:20   ------------------------------\n",
      "19:01:20   average mean squared error: 0.0950073\n",
      "19:01:20   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:20   Epoch 7 begin\n",
      "19:01:27   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:27   mean squared error: 0.092882\n",
      "19:01:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:29   Epoch 7 end\n",
      "19:01:29   duration: 9.88 secs\n",
      "19:01:29   speed: 6.58 batch / sec\n",
      "19:01:29   ETA: 25.01 secs\n",
      "19:01:29   max GPU memory: 1502.9 MiB\n",
      "19:01:29   ------------------------------\n",
      "19:01:29   average mean squared error: 0.093627\n",
      "19:01:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:29   Epoch 8 begin\n",
      "19:01:40   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:40   Epoch 8 end\n",
      "19:01:40   duration: 10.48 secs\n",
      "19:01:40   speed: 6.20 batch / sec\n",
      "19:01:40   ETA: 12.28 secs\n",
      "19:01:40   max GPU memory: 1502.9 MiB\n",
      "19:01:40   ------------------------------\n",
      "19:01:40   average mean squared error: 0.0914268\n",
      "19:01:40   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:40   Epoch 9 begin\n",
      "19:01:44   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:44   mean squared error: 0.0855197\n",
      "19:01:52   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:52   Epoch 9 end\n",
      "19:01:52   duration: 12.38 secs\n",
      "19:01:52   speed: 5.25 batch / sec\n",
      "19:01:52   ETA: 0.00 secs\n",
      "19:01:52   max GPU memory: 1502.9 MiB\n",
      "19:01:52   ------------------------------\n",
      "19:01:52   average mean squared error: 0.0903643\n",
      "19:01:52   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:01:52   Evaluate on valid\n",
      "19:01:53   ------------------------------\n",
      "19:01:53   mean absolute error [scaled_effect1]: 0.293695\n",
      "19:01:53   root mean squared error [scaled_effect1]: 0.323145\n",
      "19:01:53   spearmanr [scaled_effect1]: 0.450331\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'mean absolute error [scaled_effect1]': tensor(0.2937, device='cuda:0'),\n 'root mean squared error [scaled_effect1]': tensor(0.3231, device='cuda:0'),\n 'spearmanr [scaled_effect1]': tensor(0.4503, device='cuda:0')}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchdrug import core\n",
    "\n",
    "optimizer = torch.optim.Adam(task.parameters(), lr=1e-4)\n",
    "solver = core.Engine(task, train_set, valid_set, test_set, optimizer,\n",
    "                     gpus=[0], batch_size=64)\n",
    "solver.train(num_epoch=10)\n",
    "solver.evaluate(\"valid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:01:53.863502Z",
     "start_time": "2024-02-07T10:59:35.673624Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 2: Residue-wise Property Prediction\n",
    "\n",
    "我们考虑的第二类任务是预测残基级的性质。我们以二级结构预测任务为例。\n",
    "\n",
    "我们首先通过datasets.SecondaryStructure构建数据集，在其中我们使用cb513测试集。对于残基级的任务，我们通常保留蛋白质的整个序列，所以这里我们只使用ProteinView转换。目标字段表示每个残基的二级结构（卷曲、链或螺旋），掩码字段表示每个二级结构标签是否有效。这两个字段的长度与蛋白质序列的长度相同。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:03:47   Extracting /home/weibin/protein-datasets/secondary_structure.tar.gz to /home/weibin/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing proteins from sequences:   0%|          | 0/11497 [00:00<?, ?it/s]/home/weibin/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/data/protein.py:261: UserWarning: Unknown residue symbol `X`. Treat as glycine\n",
      "  warnings.warn(\"Unknown residue symbol `%s`. Treat as glycine\" % residue)\n",
      "Constructing proteins from sequences: 100%|██████████| 11497/11497 [00:20<00:00, 549.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS3 label:  tensor([2, 2, 2, 0, 0, 0, 0, 0, 2, 2])\n",
      "Valid mask:  tensor([True, True, True, True, True, True, True, True, True, True])\n",
      "train samples: 8678, valid samples: 2170, test samples: 513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.SecondaryStructure(\"~/protein-datasets/\", atom_feature=None, bond_feature=None, residue_feature=\"default\", transform=protein_view_transform)\n",
    "train_set, valid_set, test_set = dataset.split([\"train\", \"valid\", \"cb513\"])\n",
    "print(\"SS3 label: \", dataset[0][\"graph\"].target[:10])\n",
    "print(\"Valid mask: \", dataset[0][\"graph\"].mask[:10])\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" % (len(train_set), len(valid_set), len(test_set)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:04:16.390322Z",
     "start_time": "2024-02-07T11:03:41.482112Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了进行二级结构预测，我们将CNN编码器包装在tasks.NodePropertyPrediction模块中，该模块在CNN之上添加了一个特定任务的MLP预测头。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "task = tasks.NodePropertyPrediction(model, criterion=\"ce\",\n",
    "                                    metric=(\"micro_acc\", \"macro_acc\"),\n",
    "                                    num_mlp_layer=2, num_class=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:05:13.158665Z",
     "start_time": "2024-02-07T11:05:13.153340Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们对模型进行了5个epochs的训练，大约需要5分钟的时间，最后在验证集上进行了评估。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:05:15   Preprocess training set\n",
      "19:05:16   {'batch_size': 128,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.0001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.NodePropertyPrediction',\n",
      "          'criterion': 'ce',\n",
      "          'metric': ('micro_acc', 'macro_acc'),\n",
      "          'model': {'activation': 'relu',\n",
      "                    'class': 'models.ProteinConvolutionalNetwork',\n",
      "                    'concat_hidden': False,\n",
      "                    'hidden_dims': [1024, 1024],\n",
      "                    'input_dim': 21,\n",
      "                    'kernel_size': 5,\n",
      "                    'padding': 2,\n",
      "                    'readout': 'max',\n",
      "                    'short_cut': False,\n",
      "                    'stride': 1},\n",
      "          'normalization': True,\n",
      "          'num_class': 3,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'datasets.SecondaryStructure',\n",
      "                          'path': '~/protein-datasets/',\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.ProteinView',\n",
      "                                        'keys': 'graph',\n",
      "                                        'view': 'residue'},\n",
      "                          'verbose': 1},\n",
      "              'indices': range(10984, 11497)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.SecondaryStructure',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.ProteinView',\n",
      "                                         'keys': 'graph',\n",
      "                                         'view': 'residue'},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 8678)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.SecondaryStructure',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.ProteinView',\n",
      "                                         'keys': 'graph',\n",
      "                                         'view': 'residue'},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(8678, 10848)}}\n",
      "19:05:16   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:05:16   Epoch 0 begin\n",
      "19:05:17   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:05:17   cross entropy: 1.10127\n",
      "19:05:50   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:05:50   Epoch 0 end\n",
      "19:05:50   duration: 33.95 secs\n",
      "19:05:50   speed: 2.00 batch / sec\n",
      "19:05:50   ETA: 2.26 mins\n",
      "19:05:50   max GPU memory: 4317.3 MiB\n",
      "19:05:50   ------------------------------\n",
      "19:05:50   average cross entropy: 0.969197\n",
      "19:05:50   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:05:50   Epoch 1 begin\n",
      "19:06:06   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:06:06   cross entropy: 0.859024\n",
      "19:06:25   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:06:25   Epoch 1 end\n",
      "19:06:25   duration: 34.42 secs\n",
      "19:06:25   speed: 1.98 batch / sec\n",
      "19:06:25   ETA: 1.71 mins\n",
      "19:06:25   max GPU memory: 4318.2 MiB\n",
      "19:06:25   ------------------------------\n",
      "19:06:25   average cross entropy: 0.854923\n",
      "19:06:25   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:06:25   Epoch 2 begin\n",
      "19:06:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:06:57   cross entropy: 0.836001\n",
      "19:06:59   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:06:59   Epoch 2 end\n",
      "19:06:59   duration: 34.12 secs\n",
      "19:06:59   speed: 1.99 batch / sec\n",
      "19:06:59   ETA: 1.14 mins\n",
      "19:06:59   max GPU memory: 4318.3 MiB\n",
      "19:06:59   ------------------------------\n",
      "19:06:59   average cross entropy: 0.841642\n",
      "19:06:59   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:06:59   Epoch 3 begin\n",
      "19:07:32   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:07:32   Epoch 3 end\n",
      "19:07:32   duration: 33.34 secs\n",
      "19:07:32   speed: 2.04 batch / sec\n",
      "19:07:32   ETA: 33.96 secs\n",
      "19:07:32   max GPU memory: 4318.3 MiB\n",
      "19:07:32   ------------------------------\n",
      "19:07:32   average cross entropy: 0.824457\n",
      "19:07:32   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:07:32   Epoch 4 begin\n",
      "19:07:46   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:07:47   cross entropy: 0.794821\n",
      "19:08:06   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:08:06   Epoch 4 end\n",
      "19:08:06   duration: 34.04 secs\n",
      "19:08:06   speed: 2.00 batch / sec\n",
      "19:08:06   ETA: 0.00 secs\n",
      "19:08:06   max GPU memory: 4318.3 MiB\n",
      "19:08:06   ------------------------------\n",
      "19:08:06   average cross entropy: 0.808956\n",
      "19:08:06   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:08:06   Evaluate on valid\n",
      "19:08:08   ------------------------------\n",
      "19:08:08   macro_acc: 0.649937\n",
      "19:08:08   micro_acc: 0.644319\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'micro_acc': tensor(0.6443, device='cuda:0'),\n 'macro_acc': tensor(0.6499, device='cuda:0')}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(task.parameters(), lr=1e-4)\n",
    "solver = core.Engine(task, train_set, valid_set, test_set, optimizer,\n",
    "                     gpus=[0], batch_size=128)\n",
    "solver.train(num_epoch=5)\n",
    "solver.evaluate(\"valid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:08:08.836892Z",
     "start_time": "2024-02-07T11:05:15.270464Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3: Contact Prediction\n",
    "\n",
    "我们要解决的第三个任务是预测在折叠结构中是否存在任意两个残基之间的接触，即进行接触预测。\n",
    "\n",
    "我们首先通过datasets.ProteinNet构建数据集。residue_position字段表示每个残基的三维坐标，mask字段表示每个残基位置是否有效。这两个字段的长度与蛋白质序列的长度相同。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:08:51   Extracting /home/weibin/protein-datasets/proteinnet.tar.gz to /home/weibin/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing proteins from sequences: 100%|██████████| 25557/25557 [00:43<00:00, 589.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residue position:  tensor([[ 2.0940e+00,  2.0000e-03, -1.2420e+00],\n",
      "        [ 5.1260e+00, -2.0210e+00, -2.3290e+00],\n",
      "        [ 7.5230e+00,  6.1500e-01, -3.6610e+00]])\n",
      "Valid mask:  tensor([True, True, True])\n",
      "train samples: 25299, valid samples: 224, test samples: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.ProteinNet(\"~/protein-datasets/\", atom_feature=None, bond_feature=None, residue_feature=\"default\", transform=protein_view_transform)\n",
    "train_set, valid_set, test_set = dataset.split()\n",
    "print(\"Residue position: \", dataset[0][\"graph\"].residue_position[:3])\n",
    "print(\"Valid mask: \", dataset[0][\"graph\"].mask[:3])\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" % (len(train_set), len(valid_set), len(test_set)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:09:44.497296Z",
     "start_time": "2024-02-07T11:08:43.151013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了进行接触预测，我们将CNN编码器包装在tasks.ContactPrediction模块中，该模块在CNN之上添加了一个特定任务的MLP预测头。如果两个残基之间的序列间隔大于gap，并且它们的欧氏距离在阈值内，则认为它们发生了相互作用。与之前的任务不同，现在任务中定义了最大截断长度max_length，因为接触预测任务中测试集上的截断行为不同。对于测试集，为了节省内存，我们将测试序列根据max_length分成几个块。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "task = tasks.ContactPrediction(model, max_length=500, random_truncate=True, threshold=8.0, gap=6,\n",
    "                               criterion=\"bce\", metric=(\"accuracy\", \"prec@L5\", \"prec@5\"), num_mlp_layer=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:11:06.117124Z",
     "start_time": "2024-02-07T11:11:06.071661Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "由于原始训练集包含大量样本，而在这个任务中只能使用较小的批量大小，因此我们使用包含1000个样本的原始训练集的子集进行训练。我们对模型进行了1个epoch的训练，大约需要4分钟的时间，最后在验证集上进行了评估。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:13:49   Preprocess training set\n",
      "19:13:49   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.0001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.ContactPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'gap': 6,\n",
      "          'max_length': 500,\n",
      "          'metric': ('accuracy', 'prec@L5', 'prec@5'),\n",
      "          'model': {'activation': 'relu',\n",
      "                    'class': 'models.ProteinConvolutionalNetwork',\n",
      "                    'concat_hidden': False,\n",
      "                    'hidden_dims': [1024, 1024],\n",
      "                    'input_dim': 21,\n",
      "                    'kernel_size': 5,\n",
      "                    'padding': 2,\n",
      "                    'readout': 'max',\n",
      "                    'short_cut': False,\n",
      "                    'stride': 1},\n",
      "          'num_mlp_layer': 2,\n",
      "          'random_truncate': True,\n",
      "          'threshold': 8.0,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'datasets.ProteinNet',\n",
      "                          'path': '~/protein-datasets/',\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.ProteinView',\n",
      "                                        'keys': 'graph',\n",
      "                                        'view': 'residue'},\n",
      "                          'verbose': 1},\n",
      "              'indices': range(25523, 25557)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'class': 'dataset.Subset',\n",
      "                           'dataset': {'atom_feature': None,\n",
      "                                       'bond_feature': None,\n",
      "                                       'class': 'datasets.ProteinNet',\n",
      "                                       'path': '~/protein-datasets/',\n",
      "                                       'residue_feature': 'default',\n",
      "                                       'transform': {'class': 'transforms.ProteinView',\n",
      "                                                     'keys': 'graph',\n",
      "                                                     'view': 'residue'},\n",
      "                                       'verbose': 1},\n",
      "                           'indices': range(0, 25299)},\n",
      "               'indices': [6223,\n",
      "                           121,\n",
      "                           22938,\n",
      "                           10772,\n",
      "                           12930,\n",
      "                           24301,\n",
      "                           4753,\n",
      "                           22115,\n",
      "                           17537,\n",
      "                           4489,\n",
      "                           24997,\n",
      "                           1380,\n",
      "                           1666,\n",
      "                           12002,\n",
      "                           576,\n",
      "                           16883,\n",
      "                           24245,\n",
      "                           330,\n",
      "                           3777,\n",
      "                           6069,\n",
      "                           15870,\n",
      "                           4471,\n",
      "                           13659,\n",
      "                           8890,\n",
      "                           23545,\n",
      "                           21487,\n",
      "                           16899,\n",
      "                           21605,\n",
      "                           14832,\n",
      "                           2961,\n",
      "                           4556,\n",
      "                           1615,\n",
      "                           21409,\n",
      "                           25096,\n",
      "                           9312,\n",
      "                           2463,\n",
      "                           22392,\n",
      "                           24786,\n",
      "                           19929,\n",
      "                           8266,\n",
      "                           12064,\n",
      "                           11962,\n",
      "                           4343,\n",
      "                           1622,\n",
      "                           12276,\n",
      "                           23087,\n",
      "                           15455,\n",
      "                           14532,\n",
      "                           23298,\n",
      "                           5703,\n",
      "                           15130,\n",
      "                           12465,\n",
      "                           18293,\n",
      "                           12956,\n",
      "                           16448,\n",
      "                           2782,\n",
      "                           13935,\n",
      "                           15740,\n",
      "                           24025,\n",
      "                           23210,\n",
      "                           24518,\n",
      "                           11799,\n",
      "                           6869,\n",
      "                           20563,\n",
      "                           10131,\n",
      "                           20638,\n",
      "                           6090,\n",
      "                           6559,\n",
      "                           18766,\n",
      "                           22889,\n",
      "                           7272,\n",
      "                           22173,\n",
      "                           20112,\n",
      "                           22467,\n",
      "                           16151,\n",
      "                           5803,\n",
      "                           833,\n",
      "                           9765,\n",
      "                           25181,\n",
      "                           15658,\n",
      "                           18969,\n",
      "                           11980,\n",
      "                           11691,\n",
      "                           23157,\n",
      "                           12492,\n",
      "                           6344,\n",
      "                           7682,\n",
      "                           657,\n",
      "                           13334,\n",
      "                           5891,\n",
      "                           11333,\n",
      "                           17230,\n",
      "                           22575,\n",
      "                           23677,\n",
      "                           878,\n",
      "                           6455,\n",
      "                           1094,\n",
      "                           7793,\n",
      "                           14159,\n",
      "                           20273,\n",
      "                           21133,\n",
      "                           18271,\n",
      "                           4429,\n",
      "                           15897,\n",
      "                           22588,\n",
      "                           10535,\n",
      "                           24950,\n",
      "                           10285,\n",
      "                           4755,\n",
      "                           13212,\n",
      "                           8145,\n",
      "                           19593,\n",
      "                           4654,\n",
      "                           4943,\n",
      "                           2898,\n",
      "                           710,\n",
      "                           1250,\n",
      "                           10618,\n",
      "                           17390,\n",
      "                           856,\n",
      "                           7791,\n",
      "                           15698,\n",
      "                           13934,\n",
      "                           10641,\n",
      "                           3582,\n",
      "                           2268,\n",
      "                           10944,\n",
      "                           8153,\n",
      "                           24946,\n",
      "                           3169,\n",
      "                           12610,\n",
      "                           10219,\n",
      "                           4304,\n",
      "                           489,\n",
      "                           21715,\n",
      "                           21572,\n",
      "                           17175,\n",
      "                           7370,\n",
      "                           4705,\n",
      "                           3358,\n",
      "                           21312,\n",
      "                           12538,\n",
      "                           20455,\n",
      "                           12441,\n",
      "                           10562,\n",
      "                           16492,\n",
      "                           11938,\n",
      "                           3889,\n",
      "                           23678,\n",
      "                           12206,\n",
      "                           24199,\n",
      "                           21526,\n",
      "                           24290,\n",
      "                           17239,\n",
      "                           18792,\n",
      "                           5829,\n",
      "                           2116,\n",
      "                           7561,\n",
      "                           24594,\n",
      "                           992,\n",
      "                           2789,\n",
      "                           12922,\n",
      "                           4643,\n",
      "                           1601,\n",
      "                           5906,\n",
      "                           8864,\n",
      "                           10174,\n",
      "                           19876,\n",
      "                           9597,\n",
      "                           17598,\n",
      "                           20474,\n",
      "                           2640,\n",
      "                           984,\n",
      "                           25051,\n",
      "                           24593,\n",
      "                           23817,\n",
      "                           7231,\n",
      "                           2255,\n",
      "                           9579,\n",
      "                           15928,\n",
      "                           15923,\n",
      "                           24378,\n",
      "                           17248,\n",
      "                           8560,\n",
      "                           3371,\n",
      "                           8191,\n",
      "                           25206,\n",
      "                           1612,\n",
      "                           18811,\n",
      "                           24562,\n",
      "                           2551,\n",
      "                           13201,\n",
      "                           955,\n",
      "                           4164,\n",
      "                           20433,\n",
      "                           17724,\n",
      "                           15621,\n",
      "                           7239,\n",
      "                           15111,\n",
      "                           23532,\n",
      "                           2129,\n",
      "                           20859,\n",
      "                           13033,\n",
      "                           557,\n",
      "                           16953,\n",
      "                           19515,\n",
      "                           20632,\n",
      "                           19626,\n",
      "                           15033,\n",
      "                           3617,\n",
      "                           1046,\n",
      "                           1725,\n",
      "                           7019,\n",
      "                           10790,\n",
      "                           1287,\n",
      "                           5397,\n",
      "                           3023,\n",
      "                           18645,\n",
      "                           3426,\n",
      "                           14709,\n",
      "                           15788,\n",
      "                           3748,\n",
      "                           13141,\n",
      "                           9914,\n",
      "                           3929,\n",
      "                           24889,\n",
      "                           11256,\n",
      "                           17416,\n",
      "                           18777,\n",
      "                           19702,\n",
      "                           12683,\n",
      "                           11135,\n",
      "                           6638,\n",
      "                           18139,\n",
      "                           15673,\n",
      "                           4666,\n",
      "                           15039,\n",
      "                           9239,\n",
      "                           13816,\n",
      "                           14718,\n",
      "                           2959,\n",
      "                           2819,\n",
      "                           8454,\n",
      "                           18185,\n",
      "                           22429,\n",
      "                           666,\n",
      "                           22493,\n",
      "                           20303,\n",
      "                           8960,\n",
      "                           19270,\n",
      "                           8698,\n",
      "                           9770,\n",
      "                           16512,\n",
      "                           12986,\n",
      "                           8599,\n",
      "                           21194,\n",
      "                           1131,\n",
      "                           19542,\n",
      "                           107,\n",
      "                           989,\n",
      "                           18486,\n",
      "                           19094,\n",
      "                           7951,\n",
      "                           22271,\n",
      "                           16985,\n",
      "                           17884,\n",
      "                           7080,\n",
      "                           6948,\n",
      "                           16828,\n",
      "                           19322,\n",
      "                           17501,\n",
      "                           5173,\n",
      "                           11005,\n",
      "                           24878,\n",
      "                           16555,\n",
      "                           8943,\n",
      "                           3120,\n",
      "                           5088,\n",
      "                           16421,\n",
      "                           17404,\n",
      "                           22405,\n",
      "                           21284,\n",
      "                           7319,\n",
      "                           261,\n",
      "                           19766,\n",
      "                           11822,\n",
      "                           10627,\n",
      "                           11319,\n",
      "                           20514,\n",
      "                           16675,\n",
      "                           12025,\n",
      "                           1002,\n",
      "                           22363,\n",
      "                           8279,\n",
      "                           2528,\n",
      "                           15591,\n",
      "                           3565,\n",
      "                           6576,\n",
      "                           9596,\n",
      "                           12118,\n",
      "                           18490,\n",
      "                           11580,\n",
      "                           11971,\n",
      "                           22300,\n",
      "                           1748,\n",
      "                           14121,\n",
      "                           8370,\n",
      "                           16620,\n",
      "                           4790,\n",
      "                           23544,\n",
      "                           5402,\n",
      "                           7035,\n",
      "                           19906,\n",
      "                           10405,\n",
      "                           8445,\n",
      "                           19779,\n",
      "                           24612,\n",
      "                           7351,\n",
      "                           10597,\n",
      "                           11812,\n",
      "                           15893,\n",
      "                           11246,\n",
      "                           21555,\n",
      "                           14942,\n",
      "                           4599,\n",
      "                           16138,\n",
      "                           12382,\n",
      "                           19577,\n",
      "                           20970,\n",
      "                           7702,\n",
      "                           23313,\n",
      "                           5857,\n",
      "                           2513,\n",
      "                           23917,\n",
      "                           17031,\n",
      "                           20210,\n",
      "                           113,\n",
      "                           2744,\n",
      "                           12634,\n",
      "                           6171,\n",
      "                           16866,\n",
      "                           22483,\n",
      "                           20199,\n",
      "                           2892,\n",
      "                           8229,\n",
      "                           23815,\n",
      "                           20964,\n",
      "                           11369,\n",
      "                           16720,\n",
      "                           14292,\n",
      "                           8200,\n",
      "                           4263,\n",
      "                           13971,\n",
      "                           9873,\n",
      "                           6862,\n",
      "                           746,\n",
      "                           10443,\n",
      "                           20051,\n",
      "                           23073,\n",
      "                           3376,\n",
      "                           5298,\n",
      "                           16848,\n",
      "                           4344,\n",
      "                           2921,\n",
      "                           6080,\n",
      "                           7026,\n",
      "                           5374,\n",
      "                           11964,\n",
      "                           23982,\n",
      "                           19636,\n",
      "                           13661,\n",
      "                           20425,\n",
      "                           1908,\n",
      "                           5861,\n",
      "                           19205,\n",
      "                           13263,\n",
      "                           16457,\n",
      "                           7221,\n",
      "                           11151,\n",
      "                           23013,\n",
      "                           17662,\n",
      "                           12731,\n",
      "                           13422,\n",
      "                           14405,\n",
      "                           14057,\n",
      "                           24602,\n",
      "                           24767,\n",
      "                           22585,\n",
      "                           13779,\n",
      "                           15946,\n",
      "                           5863,\n",
      "                           19998,\n",
      "                           16357,\n",
      "                           2443,\n",
      "                           22959,\n",
      "                           25108,\n",
      "                           20292,\n",
      "                           22826,\n",
      "                           23527,\n",
      "                           18970,\n",
      "                           11892,\n",
      "                           17011,\n",
      "                           19773,\n",
      "                           13568,\n",
      "                           1897,\n",
      "                           9362,\n",
      "                           22825,\n",
      "                           10569,\n",
      "                           2638,\n",
      "                           564,\n",
      "                           14757,\n",
      "                           23893,\n",
      "                           560,\n",
      "                           13676,\n",
      "                           14479,\n",
      "                           6056,\n",
      "                           23096,\n",
      "                           13645,\n",
      "                           368,\n",
      "                           23566,\n",
      "                           21558,\n",
      "                           6460,\n",
      "                           20468,\n",
      "                           1211,\n",
      "                           20173,\n",
      "                           21308,\n",
      "                           7935,\n",
      "                           9598,\n",
      "                           1461,\n",
      "                           13252,\n",
      "                           7979,\n",
      "                           13529,\n",
      "                           18780,\n",
      "                           17685,\n",
      "                           4989,\n",
      "                           9132,\n",
      "                           24452,\n",
      "                           16487,\n",
      "                           4296,\n",
      "                           186,\n",
      "                           20810,\n",
      "                           4486,\n",
      "                           22757,\n",
      "                           16832,\n",
      "                           15835,\n",
      "                           1145,\n",
      "                           6701,\n",
      "                           11552,\n",
      "                           5742,\n",
      "                           12781,\n",
      "                           24273,\n",
      "                           10114,\n",
      "                           2305,\n",
      "                           7406,\n",
      "                           9353,\n",
      "                           7971,\n",
      "                           23685,\n",
      "                           834,\n",
      "                           12334,\n",
      "                           20770,\n",
      "                           16385,\n",
      "                           21814,\n",
      "                           20523,\n",
      "                           5896,\n",
      "                           16669,\n",
      "                           24905,\n",
      "                           11499,\n",
      "                           1662,\n",
      "                           13476,\n",
      "                           12042,\n",
      "                           16461,\n",
      "                           8107,\n",
      "                           2733,\n",
      "                           13469,\n",
      "                           22948,\n",
      "                           5572,\n",
      "                           838,\n",
      "                           3003,\n",
      "                           22675,\n",
      "                           2747,\n",
      "                           16051,\n",
      "                           13293,\n",
      "                           18298,\n",
      "                           19891,\n",
      "                           25142,\n",
      "                           1326,\n",
      "                           21415,\n",
      "                           9842,\n",
      "                           897,\n",
      "                           19726,\n",
      "                           13191,\n",
      "                           19721,\n",
      "                           5500,\n",
      "                           2176,\n",
      "                           7346,\n",
      "                           10838,\n",
      "                           16769,\n",
      "                           21700,\n",
      "                           22891,\n",
      "                           22322,\n",
      "                           23209,\n",
      "                           21247,\n",
      "                           9343,\n",
      "                           9534,\n",
      "                           15273,\n",
      "                           16030,\n",
      "                           10963,\n",
      "                           18314,\n",
      "                           17645,\n",
      "                           20386,\n",
      "                           1293,\n",
      "                           22369,\n",
      "                           8556,\n",
      "                           8497,\n",
      "                           9736,\n",
      "                           19634,\n",
      "                           10774,\n",
      "                           14188,\n",
      "                           24577,\n",
      "                           16813,\n",
      "                           2064,\n",
      "                           13929,\n",
      "                           22227,\n",
      "                           13132,\n",
      "                           15808,\n",
      "                           8966,\n",
      "                           10476,\n",
      "                           3801,\n",
      "                           7255,\n",
      "                           3232,\n",
      "                           17931,\n",
      "                           22071,\n",
      "                           24951,\n",
      "                           5854,\n",
      "                           20161,\n",
      "                           17688,\n",
      "                           11537,\n",
      "                           10286,\n",
      "                           3932,\n",
      "                           4968,\n",
      "                           2774,\n",
      "                           13489,\n",
      "                           4443,\n",
      "                           18999,\n",
      "                           8971,\n",
      "                           19552,\n",
      "                           8127,\n",
      "                           4286,\n",
      "                           10919,\n",
      "                           8716,\n",
      "                           24027,\n",
      "                           10030,\n",
      "                           22199,\n",
      "                           21990,\n",
      "                           15940,\n",
      "                           17358,\n",
      "                           2765,\n",
      "                           21773,\n",
      "                           4314,\n",
      "                           8021,\n",
      "                           12304,\n",
      "                           1164,\n",
      "                           22949,\n",
      "                           25157,\n",
      "                           16729,\n",
      "                           11039,\n",
      "                           16454,\n",
      "                           782,\n",
      "                           8182,\n",
      "                           15179,\n",
      "                           4101,\n",
      "                           24954,\n",
      "                           5265,\n",
      "                           5451,\n",
      "                           7315,\n",
      "                           13518,\n",
      "                           21559,\n",
      "                           13796,\n",
      "                           19676,\n",
      "                           9119,\n",
      "                           166,\n",
      "                           22348,\n",
      "                           3638,\n",
      "                           17511,\n",
      "                           12924,\n",
      "                           13394,\n",
      "                           10925,\n",
      "                           23186,\n",
      "                           4598,\n",
      "                           18439,\n",
      "                           24333,\n",
      "                           17299,\n",
      "                           18248,\n",
      "                           4392,\n",
      "                           12648,\n",
      "                           191,\n",
      "                           502,\n",
      "                           10968,\n",
      "                           20692,\n",
      "                           12617,\n",
      "                           10230,\n",
      "                           22994,\n",
      "                           12844,\n",
      "                           21238,\n",
      "                           10994,\n",
      "                           22849,\n",
      "                           19847,\n",
      "                           5579,\n",
      "                           14925,\n",
      "                           18557,\n",
      "                           23502,\n",
      "                           3061,\n",
      "                           5723,\n",
      "                           11257,\n",
      "                           15516,\n",
      "                           15686,\n",
      "                           8581,\n",
      "                           1203,\n",
      "                           14229,\n",
      "                           20090,\n",
      "                           1941,\n",
      "                           2312,\n",
      "                           22057,\n",
      "                           1470,\n",
      "                           18828,\n",
      "                           21980,\n",
      "                           18081,\n",
      "                           16033,\n",
      "                           14402,\n",
      "                           19682,\n",
      "                           17516,\n",
      "                           10489,\n",
      "                           12505,\n",
      "                           22383,\n",
      "                           2960,\n",
      "                           5112,\n",
      "                           2262,\n",
      "                           12658,\n",
      "                           8144,\n",
      "                           14524,\n",
      "                           8134,\n",
      "                           23927,\n",
      "                           988,\n",
      "                           24229,\n",
      "                           15604,\n",
      "                           16447,\n",
      "                           9854,\n",
      "                           18916,\n",
      "                           8082,\n",
      "                           22263,\n",
      "                           21749,\n",
      "                           7401,\n",
      "                           15320,\n",
      "                           8267,\n",
      "                           14075,\n",
      "                           10362,\n",
      "                           10999,\n",
      "                           2490,\n",
      "                           9294,\n",
      "                           18149,\n",
      "                           4938,\n",
      "                           8448,\n",
      "                           19801,\n",
      "                           23560,\n",
      "                           23605,\n",
      "                           23270,\n",
      "                           19880,\n",
      "                           21722,\n",
      "                           24759,\n",
      "                           7734,\n",
      "                           2153,\n",
      "                           9707,\n",
      "                           10773,\n",
      "                           21480,\n",
      "                           15605,\n",
      "                           14209,\n",
      "                           19023,\n",
      "                           24176,\n",
      "                           24135,\n",
      "                           6402,\n",
      "                           22179,\n",
      "                           19375,\n",
      "                           2633,\n",
      "                           10105,\n",
      "                           23052,\n",
      "                           7163,\n",
      "                           7943,\n",
      "                           6700,\n",
      "                           5117,\n",
      "                           22515,\n",
      "                           9571,\n",
      "                           3951,\n",
      "                           6920,\n",
      "                           24782,\n",
      "                           11591,\n",
      "                           19013,\n",
      "                           12153,\n",
      "                           17382,\n",
      "                           4181,\n",
      "                           23078,\n",
      "                           21493,\n",
      "                           9230,\n",
      "                           21302,\n",
      "                           7468,\n",
      "                           14533,\n",
      "                           16394,\n",
      "                           22465,\n",
      "                           22605,\n",
      "                           4432,\n",
      "                           15048,\n",
      "                           7773,\n",
      "                           6600,\n",
      "                           14976,\n",
      "                           11487,\n",
      "                           8788,\n",
      "                           17363,\n",
      "                           12273,\n",
      "                           18745,\n",
      "                           10557,\n",
      "                           9944,\n",
      "                           10873,\n",
      "                           12087,\n",
      "                           24000,\n",
      "                           13163,\n",
      "                           5813,\n",
      "                           19385,\n",
      "                           19015,\n",
      "                           14152,\n",
      "                           11351,\n",
      "                           6969,\n",
      "                           12989,\n",
      "                           16995,\n",
      "                           11166,\n",
      "                           198,\n",
      "                           19054,\n",
      "                           13606,\n",
      "                           5448,\n",
      "                           23600,\n",
      "                           16178,\n",
      "                           24146,\n",
      "                           19384,\n",
      "                           12031,\n",
      "                           14012,\n",
      "                           6277,\n",
      "                           3540,\n",
      "                           14011,\n",
      "                           9759,\n",
      "                           5129,\n",
      "                           7407,\n",
      "                           6413,\n",
      "                           17916,\n",
      "                           3784,\n",
      "                           19222,\n",
      "                           8038,\n",
      "                           4015,\n",
      "                           2874,\n",
      "                           15472,\n",
      "                           13749,\n",
      "                           9513,\n",
      "                           19933,\n",
      "                           4750,\n",
      "                           11065,\n",
      "                           5644,\n",
      "                           23555,\n",
      "                           19215,\n",
      "                           16015,\n",
      "                           9098,\n",
      "                           14736,\n",
      "                           5638,\n",
      "                           7478,\n",
      "                           18160,\n",
      "                           4701,\n",
      "                           9895,\n",
      "                           6186,\n",
      "                           3867,\n",
      "                           1718,\n",
      "                           7228,\n",
      "                           8530,\n",
      "                           15109,\n",
      "                           11057,\n",
      "                           17304,\n",
      "                           4142,\n",
      "                           3254,\n",
      "                           39,\n",
      "                           17888,\n",
      "                           21237,\n",
      "                           15431,\n",
      "                           1928,\n",
      "                           8593,\n",
      "                           5156,\n",
      "                           14255,\n",
      "                           16096,\n",
      "                           14935,\n",
      "                           4545,\n",
      "                           7011,\n",
      "                           4758,\n",
      "                           7865,\n",
      "                           4921,\n",
      "                           8311,\n",
      "                           8692,\n",
      "                           11425,\n",
      "                           6003,\n",
      "                           3285,\n",
      "                           15490,\n",
      "                           11310,\n",
      "                           15790,\n",
      "                           13580,\n",
      "                           16811,\n",
      "                           23552,\n",
      "                           6353,\n",
      "                           19537,\n",
      "                           12460,\n",
      "                           6650,\n",
      "                           6973,\n",
      "                           12461,\n",
      "                           17451,\n",
      "                           22782,\n",
      "                           3255,\n",
      "                           438,\n",
      "                           11145,\n",
      "                           6951,\n",
      "                           23136,\n",
      "                           12929,\n",
      "                           16366,\n",
      "                           4312,\n",
      "                           2271,\n",
      "                           16005,\n",
      "                           11284,\n",
      "                           11189,\n",
      "                           14403,\n",
      "                           3675,\n",
      "                           22536,\n",
      "                           4551,\n",
      "                           15954,\n",
      "                           5199,\n",
      "                           7553,\n",
      "                           16107,\n",
      "                           11813,\n",
      "                           12174,\n",
      "                           1798,\n",
      "                           24907,\n",
      "                           11462,\n",
      "                           5942,\n",
      "                           14980,\n",
      "                           9045,\n",
      "                           6565,\n",
      "                           6061,\n",
      "                           20592,\n",
      "                           21132,\n",
      "                           8277,\n",
      "                           19923,\n",
      "                           4630,\n",
      "                           13491,\n",
      "                           11442,\n",
      "                           24607,\n",
      "                           6955,\n",
      "                           14543,\n",
      "                           14974,\n",
      "                           20446,\n",
      "                           15027,\n",
      "                           2013,\n",
      "                           20250,\n",
      "                           4913,\n",
      "                           9368,\n",
      "                           14889,\n",
      "                           11912,\n",
      "                           10703,\n",
      "                           4781,\n",
      "                           16822,\n",
      "                           4497,\n",
      "                           21865,\n",
      "                           10501,\n",
      "                           21752,\n",
      "                           11546,\n",
      "                           15363,\n",
      "                           17583,\n",
      "                           11015,\n",
      "                           22775,\n",
      "                           20725,\n",
      "                           12923,\n",
      "                           610,\n",
      "                           19673,\n",
      "                           23834,\n",
      "                           20486,\n",
      "                           9876,\n",
      "                           20802,\n",
      "                           25012,\n",
      "                           7609,\n",
      "                           22045,\n",
      "                           22520,\n",
      "                           21543,\n",
      "                           15308,\n",
      "                           5741,\n",
      "                           19617,\n",
      "                           20477,\n",
      "                           9344,\n",
      "                           3209,\n",
      "                           9932,\n",
      "                           15636,\n",
      "                           17053,\n",
      "                           12595,\n",
      "                           6157,\n",
      "                           3480,\n",
      "                           9930,\n",
      "                           13297,\n",
      "                           3656,\n",
      "                           6428,\n",
      "                           11887,\n",
      "                           6705,\n",
      "                           11515,\n",
      "                           9365,\n",
      "                           8930,\n",
      "                           23276,\n",
      "                           13705,\n",
      "                           19722,\n",
      "                           13670,\n",
      "                           19152,\n",
      "                           5860,\n",
      "                           23081,\n",
      "                           967,\n",
      "                           10805,\n",
      "                           15529,\n",
      "                           7948,\n",
      "                           4822,\n",
      "                           12601,\n",
      "                           18903,\n",
      "                           12266,\n",
      "                           14842,\n",
      "                           18161,\n",
      "                           6554,\n",
      "                           1362,\n",
      "                           6335,\n",
      "                           5362,\n",
      "                           9345,\n",
      "                           11077,\n",
      "                           10238,\n",
      "                           6376,\n",
      "                           12805,\n",
      "                           1884,\n",
      "                           10099,\n",
      "                           16329,\n",
      "                           19259,\n",
      "                           3452,\n",
      "                           21245,\n",
      "                           12186,\n",
      "                           19739,\n",
      "                           14430,\n",
      "                           403,\n",
      "                           16026,\n",
      "                           11739,\n",
      "                           5927,\n",
      "                           20355,\n",
      "                           1430,\n",
      "                           21126,\n",
      "                           15865,\n",
      "                           9351,\n",
      "                           24063,\n",
      "                           20649,\n",
      "                           7714,\n",
      "                           21693,\n",
      "                           6628,\n",
      "                           18014,\n",
      "                           13702,\n",
      "                           20790,\n",
      "                           13261,\n",
      "                           9500,\n",
      "                           21156,\n",
      "                           12969,\n",
      "                           17588,\n",
      "                           4022,\n",
      "                           10358,\n",
      "                           21798,\n",
      "                           16937,\n",
      "                           8064,\n",
      "                           12239,\n",
      "                           23404,\n",
      "                           14485,\n",
      "                           12062,\n",
      "                           6972,\n",
      "                           5411,\n",
      "                           8902,\n",
      "                           18899,\n",
      "                           21783,\n",
      "                           20747,\n",
      "                           13251,\n",
      "                           19213,\n",
      "                           20976,\n",
      "                           19641,\n",
      "                           7162,\n",
      "                           8252,\n",
      "                           25261,\n",
      "                           7544,\n",
      "                           22479,\n",
      "                           13608,\n",
      "                           23083,\n",
      "                           19881,\n",
      "                           1668,\n",
      "                           14214,\n",
      "                           24210,\n",
      "                           16240]},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.ProteinNet',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.ProteinView',\n",
      "                                         'keys': 'graph',\n",
      "                                         'view': 'residue'},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(25299, 25523)}}\n",
      "19:13:49   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:13:49   Epoch 0 begin\n",
      "19:13:49   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:13:49   binary cross entropy: 0.337945\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 208.00 MiB (GPU 0; 23.87 GiB total capacity; 9.24 GiB already allocated; 76.94 MiB free; 9.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m sub_train_set \u001B[38;5;241m=\u001B[39m torch_data\u001B[38;5;241m.\u001B[39mrandom_split(train_set, [\u001B[38;5;241m1000\u001B[39m, \u001B[38;5;28mlen\u001B[39m(train_set) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1000\u001B[39m])[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      5\u001B[0m solver \u001B[38;5;241m=\u001B[39m core\u001B[38;5;241m.\u001B[39mEngine(task, sub_train_set, valid_set, test_set, optimizer,\n\u001B[1;32m      6\u001B[0m                      gpus\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m], batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m \u001B[43msolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m solver\u001B[38;5;241m.\u001B[39mevaluate(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/core/engine.py:155\u001B[0m, in \u001B[0;36mEngine.train\u001B[0;34m(self, num_epoch, batch_per_epoch)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    153\u001B[0m     batch \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mcuda(batch, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 155\u001B[0m loss, metric \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mrequires_grad:\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt require grad. Did you define any loss in the task?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/tasks/contact_prediction.py:81\u001B[0m, in \u001B[0;36mContactPrediction.forward\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     78\u001B[0m metric \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     80\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtruncate(batch)\n\u001B[0;32m---> 81\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget(batch)\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m criterion, weight \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/tasks/contact_prediction.py:123\u001B[0m, in \u001B[0;36mContactPrediction.predict\u001B[0;34m(self, batch, all_loss, metric)\u001B[0m\n\u001B[1;32m    121\u001B[0m     diff \u001B[38;5;241m=\u001B[39m (output[node_in] \u001B[38;5;241m-\u001B[39m output[node_out])\u001B[38;5;241m.\u001B[39mabs()\n\u001B[1;32m    122\u001B[0m     pairwise_features \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((prod, diff), \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 123\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpairwise_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pred\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/layers/common.py:64\u001B[0m, in \u001B[0;36mMultiLayerPerceptron.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     62\u001B[0m     x \u001B[38;5;241m=\u001B[39m hidden\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     63\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_norms[i](x)\u001B[38;5;241m.\u001B[39mview_as(hidden)\n\u001B[0;32m---> 64\u001B[0m hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactivation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout:\n\u001B[1;32m     66\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden)\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/functional.py:1299\u001B[0m, in \u001B[0;36mrelu\u001B[0;34m(input, inplace)\u001B[0m\n\u001B[1;32m   1297\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu_(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m   1298\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1299\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 208.00 MiB (GPU 0; 23.87 GiB total capacity; 9.24 GiB already allocated; 76.94 MiB free; 9.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torch.utils import data as torch_data\n",
    "\n",
    "optimizer = torch.optim.Adam(task.parameters(), lr=1e-4)\n",
    "sub_train_set = torch_data.random_split(train_set, [1000, len(train_set) - 1000])[0]\n",
    "solver = core.Engine(task, sub_train_set, valid_set, test_set, optimizer,\n",
    "                     gpus=[0], batch_size=1)\n",
    "solver.train(num_epoch=1)\n",
    "solver.evaluate(\"valid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:13:50.015660Z",
     "start_time": "2024-02-07T11:13:49.719339Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 4: Protein-Protein Interaction (PPI) Prediction\n",
    "\n",
    "我们考虑的第四个任务是预测两个相互作用蛋白质的结合亲和力，即进行PPI亲和力预测。\n",
    "\n",
    "我们首先通过datasets.PPIAffinity构建数据集，其中每个样本是一对蛋白质，并且与一个连续标签相关联，表示结合亲和力。由于我们现在需要对两个蛋白质进行转换，因此我们需要在转换函数中指定键值。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:14:32   Extracting /home/weibin/protein-datasets/ppi_affinity.zip to /home/weibin/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing proteins from sequences: 100%|██████████| 2950/2950 [00:09<00:00, 315.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of first sample:  -12.2937\n",
      "train samples: 2421, valid samples: 203, test samples: 326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "truncate_transform_ = transforms.TruncateProtein(max_length=200, keys=(\"graph1\", \"graph2\"))\n",
    "protein_view_transform_ = transforms.ProteinView(view=\"residue\", keys=(\"graph1\", \"graph2\"))\n",
    "transform_ = transforms.Compose([truncate_transform_, protein_view_transform_])\n",
    "dataset = datasets.PPIAffinity(\"~/protein-datasets/\", atom_feature=None, bond_feature=None, residue_feature=\"default\", transform=transform_)\n",
    "train_set, valid_set, test_set = dataset.split()\n",
    "print(\"The label of first sample: \", dataset[0][dataset.target_fields[0]])\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" % (len(train_set), len(valid_set), len(test_set)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:14:42.426207Z",
     "start_time": "2024-02-07T11:14:32.818181Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了进行PPI亲和力预测，我们将CNN编码器包装在tasks.InteractionPrediction模块中，该模块在CNN之上添加了一个特定任务的MLP预测头。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "task = tasks.InteractionPrediction(model, task=dataset.tasks,\n",
    "                                   criterion=\"mse\", metric=(\"mae\", \"rmse\", \"spearmanr\"),\n",
    "                                   normalization=False, num_mlp_layer=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:14:42.427801Z",
     "start_time": "2024-02-07T11:14:42.425979Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们将模型训练10个epoch，大约需要2分钟的时间，最后在验证集上进行评估。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:14:42   Preprocess training set\n",
      "19:14:47   {'batch_size': 64,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.0001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.InteractionPrediction',\n",
      "          'criterion': 'mse',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('mae', 'rmse', 'spearmanr'),\n",
      "          'model': {'activation': 'relu',\n",
      "                    'class': 'models.ProteinConvolutionalNetwork',\n",
      "                    'concat_hidden': False,\n",
      "                    'hidden_dims': [1024, 1024],\n",
      "                    'input_dim': 21,\n",
      "                    'kernel_size': 5,\n",
      "                    'padding': 2,\n",
      "                    'readout': 'max',\n",
      "                    'short_cut': False,\n",
      "                    'stride': 1},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'task': ['interaction'],\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'datasets.PPIAffinity',\n",
      "                          'path': '~/protein-datasets/',\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb1d4128ee0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7fb1d4128b20>]},\n",
      "                          'verbose': 1},\n",
      "              'indices': range(2624, 2950)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.PPIAffinity',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb1d4128ee0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fb1d4128b20>]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 2421)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.PPIAffinity',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb1d4128ee0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fb1d4128b20>]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(2421, 2624)}}\n",
      "19:14:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:14:47   Epoch 0 begin\n",
      "19:14:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:14:47   mean squared error: 148.038\n",
      "19:14:55   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:14:55   Epoch 0 end\n",
      "19:14:55   duration: 8.37 secs\n",
      "19:14:55   speed: 4.54 batch / sec\n",
      "19:14:55   ETA: 1.26 mins\n",
      "19:14:55   max GPU memory: 10141.7 MiB\n",
      "19:14:55   ------------------------------\n",
      "19:14:55   average mean squared error: 23.0769\n",
      "19:14:55   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:14:55   Epoch 1 begin\n",
      "19:15:03   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:03   Epoch 1 end\n",
      "19:15:03   duration: 7.85 secs\n",
      "19:15:03   speed: 4.84 batch / sec\n",
      "19:15:03   ETA: 1.08 mins\n",
      "19:15:03   max GPU memory: 1627.9 MiB\n",
      "19:15:03   ------------------------------\n",
      "19:15:03   average mean squared error: 10.6846\n",
      "19:15:03   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:03   Epoch 2 begin\n",
      "19:15:08   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:08   mean squared error: 7.79656\n",
      "19:15:11   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:11   Epoch 2 end\n",
      "19:15:11   duration: 7.65 secs\n",
      "19:15:11   speed: 4.97 batch / sec\n",
      "19:15:11   ETA: 55.71 secs\n",
      "19:15:11   max GPU memory: 1628.5 MiB\n",
      "19:15:11   ------------------------------\n",
      "19:15:11   average mean squared error: 7.99704\n",
      "19:15:11   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:11   Epoch 3 begin\n",
      "19:15:19   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:19   Epoch 3 end\n",
      "19:15:19   duration: 7.85 secs\n",
      "19:15:19   speed: 4.84 batch / sec\n",
      "19:15:19   ETA: 47.59 secs\n",
      "19:15:19   max GPU memory: 1627.9 MiB\n",
      "19:15:19   ------------------------------\n",
      "19:15:19   average mean squared error: 5.79498\n",
      "19:15:19   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:19   Epoch 4 begin\n",
      "19:15:26   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:26   Epoch 4 end\n",
      "19:15:26   duration: 7.03 secs\n",
      "19:15:26   speed: 5.41 batch / sec\n",
      "19:15:26   ETA: 38.75 secs\n",
      "19:15:26   max GPU memory: 1627.9 MiB\n",
      "19:15:26   ------------------------------\n",
      "19:15:26   average mean squared error: 4.61794\n",
      "19:15:26   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:26   Epoch 5 begin\n",
      "19:15:28   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:28   mean squared error: 3.99152\n",
      "19:15:34   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:34   Epoch 5 end\n",
      "19:15:34   duration: 8.16 secs\n",
      "19:15:34   speed: 4.65 batch / sec\n",
      "19:15:34   ETA: 31.28 secs\n",
      "19:15:34   max GPU memory: 1627.9 MiB\n",
      "19:15:34   ------------------------------\n",
      "19:15:34   average mean squared error: 3.93496\n",
      "19:15:34   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:34   Epoch 6 begin\n",
      "19:15:41   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:41   Epoch 6 end\n",
      "19:15:41   duration: 7.51 secs\n",
      "19:15:41   speed: 5.06 batch / sec\n",
      "19:15:41   ETA: 23.32 secs\n",
      "19:15:41   max GPU memory: 1627.9 MiB\n",
      "19:15:41   ------------------------------\n",
      "19:15:41   average mean squared error: 3.61658\n",
      "19:15:41   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:41   Epoch 7 begin\n",
      "19:15:48   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:48   mean squared error: 2.86809\n",
      "19:15:48   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:48   Epoch 7 end\n",
      "19:15:48   duration: 6.98 secs\n",
      "19:15:48   speed: 5.45 batch / sec\n",
      "19:15:48   ETA: 15.35 secs\n",
      "19:15:48   max GPU memory: 1627.9 MiB\n",
      "19:15:48   ------------------------------\n",
      "19:15:48   average mean squared error: 3.48173\n",
      "19:15:48   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:48   Epoch 8 begin\n",
      "19:15:56   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:56   Epoch 8 end\n",
      "19:15:56   duration: 7.25 secs\n",
      "19:15:56   speed: 5.24 batch / sec\n",
      "19:15:56   ETA: 7.63 secs\n",
      "19:15:56   max GPU memory: 1627.9 MiB\n",
      "19:15:56   ------------------------------\n",
      "19:15:56   average mean squared error: 3.33327\n",
      "19:15:56   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:15:56   Epoch 9 begin\n",
      "19:16:04   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:16:04   Epoch 9 end\n",
      "19:16:04   duration: 8.47 secs\n",
      "19:16:04   speed: 4.49 batch / sec\n",
      "19:16:04   ETA: 0.00 secs\n",
      "19:16:04   max GPU memory: 1628.1 MiB\n",
      "19:16:04   ------------------------------\n",
      "19:16:04   average mean squared error: 3.17735\n",
      "19:16:04   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:16:04   Evaluate on valid\n",
      "19:16:05   ------------------------------\n",
      "19:16:05   mean absolute error [interaction]: 2.16064\n",
      "19:16:05   root mean squared error [interaction]: 2.81175\n",
      "19:16:05   spearmanr [interaction]: 0.501698\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'mean absolute error [interaction]': tensor(2.1606, device='cuda:0'),\n 'root mean squared error [interaction]': tensor(2.8118, device='cuda:0'),\n 'spearmanr [interaction]': tensor(0.5017, device='cuda:0')}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(task.parameters(), lr=1e-4)\n",
    "solver = core.Engine(task, train_set, valid_set, test_set, optimizer,\n",
    "                     gpus=[0], batch_size=64)\n",
    "solver.train(num_epoch=10)\n",
    "solver.evaluate(\"valid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:16:04.997063Z",
     "start_time": "2024-02-07T11:14:42.426139Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 5: Protein-Ligand Interaction (PLI) Prediction\n",
    "\n",
    "我们考虑的第五个任务是预测蛋白质和小分子（即配体）的结合亲和力。我们以BindingDB上的PLI预测为例。\n",
    "\n",
    "我们首先通过datasets.BindingDB构建数据集，其中每个样本是一对蛋白质和配体，并且与一个连续标签相关联，表示结合亲和力。我们使用holdout_test集作为测试集。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:16:05   Extracting /home/weibin/protein-datasets/BindingDB_Kd.tar.gz to /home/weibin/protein-datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing proteins from sequences:  29%|██▊       | 5091/17819 [00:32<01:14, 169.92it/s]/home/weibin/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/data/feature.py:42: UserWarning: Unknown value `Na`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "Constructing proteins from sequences:  31%|███       | 5562/17819 [00:34<01:12, 168.72it/s]/home/weibin/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/data/feature.py:42: UserWarning: Unknown value `Fe`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "Constructing proteins from sequences:  68%|██████▊   | 12186/17819 [01:16<00:30, 181.78it/s]/home/weibin/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/data/feature.py:42: UserWarning: Unknown value `Mn`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "Constructing proteins from sequences:  74%|███████▍  | 13262/17819 [01:22<00:26, 174.46it/s]/home/weibin/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/data/feature.py:42: UserWarning: Unknown value `Li`\n",
      "  warnings.warn(\"Unknown value `%s`\" % x)\n",
      "Constructing proteins from sequences: 100%|██████████| 17819/17819 [01:54<00:00, 155.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of first sample:  5.823908740944319\n",
      "train samples: 7900, valid samples: 878, test samples: 5230\n"
     ]
    }
   ],
   "source": [
    "truncate_transform_ = transforms.TruncateProtein(max_length=200, keys=\"graph1\")\n",
    "protein_view_transform_ = transforms.ProteinView(view=\"residue\", keys=\"graph1\")\n",
    "transform_ = transforms.Compose([truncate_transform_, protein_view_transform_])\n",
    "dataset = datasets.BindingDB(\"~/protein-datasets/\", atom_feature=None, bond_feature=None, residue_feature=\"default\", transform=transform_)\n",
    "train_set, valid_set, test_set = dataset.split([\"train\", \"valid\", \"holdout_test\"])\n",
    "print(\"The label of first sample: \", dataset[0][dataset.target_fields[0]])\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" % (len(train_set), len(valid_set), len(test_set)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:18:00.757860Z",
     "start_time": "2024-02-07T11:16:04.993686Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了进行PLI预测，我们需要一个额外的配体图编码器来提取配体的表示。我们将一个4层的图同构网络（GIN）定义为配体图编码器。然后，我们将CNN编码器和GIN编码器包装在tasks.InteractionPrediction模块中，该模块在CNN和GIN之上添加了一个特定任务的MLP预测头。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model2 = models.GIN(input_dim=66,\n",
    "                    hidden_dims=[256, 256, 256, 256],\n",
    "                    batch_norm=True, short_cut=True, concat_hidden=True)\n",
    "\n",
    "task = tasks.InteractionPrediction(model, model2=model2, task=dataset.tasks,\n",
    "                                   criterion=\"mse\", metric=(\"mae\", \"rmse\", \"spearmanr\"),\n",
    "                                   normalization=False, num_mlp_layer=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:18:00.766722Z",
     "start_time": "2024-02-07T11:18:00.757417Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们将模型训练5个epoch，大约需要3分钟的时间，最后在验证集上进行评估。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:18:00   Preprocess training set\n",
      "19:18:15   {'batch_size': 16,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.0001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.InteractionPrediction',\n",
      "          'criterion': 'mse',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('mae', 'rmse', 'spearmanr'),\n",
      "          'model': {'activation': 'relu',\n",
      "                    'class': 'models.ProteinConvolutionalNetwork',\n",
      "                    'concat_hidden': False,\n",
      "                    'hidden_dims': [1024, 1024],\n",
      "                    'input_dim': 21,\n",
      "                    'kernel_size': 5,\n",
      "                    'padding': 2,\n",
      "                    'readout': 'max',\n",
      "                    'short_cut': False,\n",
      "                    'stride': 1},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'task': ['affinity'],\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'datasets.BindingDB',\n",
      "                          'path': '~/protein-datasets/',\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb1f5f7aca0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7fb1e7a63a90>]},\n",
      "                          'verbose': 1},\n",
      "              'indices': range(12589, 17819)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.BindingDB',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb1f5f7aca0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fb1e7a63a90>]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 7900)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'datasets.BindingDB',\n",
      "                           'path': '~/protein-datasets/',\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fb1f5f7aca0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fb1e7a63a90>]},\n",
      "                           'verbose': 1},\n",
      "               'indices': range(7900, 8778)}}\n",
      "19:18:15   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "19:18:15   Epoch 0 begin\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (482x67 and 66x256)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(task\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m)\n\u001B[1;32m      2\u001B[0m solver \u001B[38;5;241m=\u001B[39m core\u001B[38;5;241m.\u001B[39mEngine(task, train_set, valid_set, test_set, optimizer,\n\u001B[1;32m      3\u001B[0m                      gpus\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0\u001B[39m], batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43msolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m solver\u001B[38;5;241m.\u001B[39mevaluate(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/core/engine.py:155\u001B[0m, in \u001B[0;36mEngine.train\u001B[0;34m(self, num_epoch, batch_per_epoch)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    153\u001B[0m     batch \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mcuda(batch, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 155\u001B[0m loss, metric \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mrequires_grad:\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoss doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt require grad. Did you define any loss in the task?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/tasks/property_prediction.py:96\u001B[0m, in \u001B[0;36mPropertyPrediction.forward\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     93\u001B[0m all_loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[38;5;241m0\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     94\u001B[0m metric \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m---> 96\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m([t \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m batch \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask]):\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;66;03m# unlabeled data\u001B[39;00m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m all_loss, metric\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/tasks/property_prediction.py:526\u001B[0m, in \u001B[0;36mInteractionPrediction.predict\u001B[0;34m(self, batch, all_loss, metric)\u001B[0m\n\u001B[1;32m    524\u001B[0m output1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(graph1, graph1\u001B[38;5;241m.\u001B[39mnode_feature\u001B[38;5;241m.\u001B[39mfloat(), all_loss\u001B[38;5;241m=\u001B[39mall_loss, metric\u001B[38;5;241m=\u001B[39mmetric)\n\u001B[1;32m    525\u001B[0m graph2 \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph2\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 526\u001B[0m output2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_feature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mall_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    527\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp(torch\u001B[38;5;241m.\u001B[39mcat([output1[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph_feature\u001B[39m\u001B[38;5;124m\"\u001B[39m], output2[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgraph_feature\u001B[39m\u001B[38;5;124m\"\u001B[39m]], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnormalization:\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/models/gin.py:76\u001B[0m, in \u001B[0;36mGraphIsomorphismNetwork.forward\u001B[0;34m(self, graph, input, all_loss, metric)\u001B[0m\n\u001B[1;32m     73\u001B[0m layer_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 76\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshort_cut \u001B[38;5;129;01mand\u001B[39;00m hidden\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m layer_input\u001B[38;5;241m.\u001B[39mshape:\n\u001B[1;32m     78\u001B[0m         hidden \u001B[38;5;241m=\u001B[39m hidden \u001B[38;5;241m+\u001B[39m layer_input\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/layers/conv.py:92\u001B[0m, in \u001B[0;36mMessagePassingBase.forward\u001B[0;34m(self, graph, input)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     91\u001B[0m     update \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage_and_aggregate(graph, \u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m---> 92\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/layers/conv.py:351\u001B[0m, in \u001B[0;36mGraphIsomorphismConv.combine\u001B[0;34m(self, input, update)\u001B[0m\n\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcombine\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, update):\n\u001B[0;32m--> 351\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    352\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_norm:\n\u001B[1;32m    353\u001B[0m         output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_norm(output)\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torchdrug/layers/common.py:59\u001B[0m, in \u001B[0;36mMultiLayerPerceptron.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     56\u001B[0m layer_input \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers):\n\u001B[0;32m---> 59\u001B[0m     hidden \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     61\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_norms:\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/torchdrug/lib/python3.8/site-packages/torch/nn/functional.py:1848\u001B[0m, in \u001B[0;36mlinear\u001B[0;34m(input, weight, bias)\u001B[0m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_variadic(\u001B[38;5;28minput\u001B[39m, weight, bias):\n\u001B[1;32m   1847\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(linear, (\u001B[38;5;28minput\u001B[39m, weight, bias), \u001B[38;5;28minput\u001B[39m, weight, bias\u001B[38;5;241m=\u001B[39mbias)\n\u001B[0;32m-> 1848\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (482x67 and 66x256)"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(task.parameters(), lr=1e-4)\n",
    "solver = core.Engine(task, train_set, valid_set, test_set, optimizer,\n",
    "                     gpus=[0], batch_size=16)\n",
    "solver.train(num_epoch=5)\n",
    "solver.evaluate(\"valid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-07T11:18:19.622299Z",
     "start_time": "2024-02-07T11:18:00.807164Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
